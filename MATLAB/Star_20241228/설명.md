# 3D 포즈 추정 및 좌표 변환의 수학적 배경

## 목차
1. [서론](#서론)
2. [문제 정의](#문제-정의)
3. [데이터 소스](#데이터-소스)
4. [좌표계 이해](#좌표계-이해)
5. [좌표 변환의 수학적 배경](#좌표-변환의-수학적-배경)
    - [5.1 회전 행렬](#51-회전-행렬)
    - [5.2 기준 변경(Change of Basis)](#52-기준-변경change-of-basis)
    - [5.3 상대 포즈(Relative Pose) 계산](#53-상대-포즈relative-pose-계산)
6. [좌표 변환 과정](#좌표-변환-과정)
    - [6.1 데이터 로드](#61-데이터-로드)
    - [6.2 쿼터니언을 회전 행렬로 변환](#62-쿼터니언을-회전-행렬로-변환)
    - [6.3 좌표계 정렬](#63-좌표계-정렬)
    - [6.4 상대 포즈 계산](#64-상대-포즈-계산)
7. [시각화](#시각화)
8. [결론](#결론)
9. [참고 문헌](#참고-문헌)

## 서론

3D 포즈 추정은 컴퓨터 비전 및 로보틱스 분야에서 중요한 역할을 합니다. 이를 통해 객체의 위치와 방향을 정확하게 파악할 수 있으며, 다양한 응용 분야에서 활용됩니다. 본 문서에서는 OptiTrack과 같은 모션 캡처 시스템에서 얻은 지상 진리 데이터(Ground Truth)와 알고리즘이 추정한 포즈 데이터를 동일한 좌표계에서 비교하기 위한 좌표 변환 과정을 수학적 배경과 함께 단계별로 설명합니다.

## 문제 정의

- **목표**: OptiTrack에서 얻은 지상 진리 데이터와 포즈 추정 알고리즘의 결과를 동일한 좌표계(OpenCV 좌표계)로 변환하여 비교 및 시각화.
- **주요 도전 과제**: 서로 다른 좌표계를 사용하는 두 데이터 소스 간의 정확한 정렬과 변환.

## 데이터 소스

1. **OptiTrack 지상 진리 데이터**:
    - ROS2 bag 파일(`.db3`)에 저장된 카메라 및 타겟의 위치와 방향 정보.
    - 쿼터니언(Quaternion) 형식의 회전 정보 포함.

2. **포즈 추정 알고리즘 데이터**:
    - JSON 파일(`.json`)에 저장된 알고리즘이 추정한 타겟의 회전 행렬과 위치 벡터.
    - OpenCV 스타일의 좌표계 사용.

## 좌표계 이해

### OptiTrack 좌표계
- **X축**: 오른쪽
- **Y축**: 위
- **Z축**: -시선 방향 (카메라가 바라보는 방향의 반대)

### OpenCV 좌표계
- **X축**: 오른쪽
- **Y축**: 아래
- **Z축**: 시선 방향 (카메라가 바라보는 방향)

두 좌표계는 X축은 동일하지만 Y축과 Z축의 방향이 반대입니다. 따라서 데이터를 정확하게 비교하기 위해서는 좌표계 변환이 필요합니다.

## 좌표 변환의 수학적 배경

### 5.1 회전 행렬

회전 행렬(Rotation Matrix)은 3D 공간에서 객체의 회전을 나타내는 3x3 행렬입니다. 기본적인 회전 행렬은 다음과 같은 성질을 가집니다:

- **직교성**: $R^T \cdot R = I$, 여기서 $R^T$는 회전 행렬의 전치 행렬, $I$는 단위 행렬.
- **단위 행렬의 행렬식**: $\det(R) = 1$.

쿼터니언을 회전 행렬로 변환하는 것은 회전 정보를 행렬 형태로 표현하는 중요한 과정입니다.

### 5.2 기준 변경(Change of Basis)

기준 변경은 한 좌표계에서 다른 좌표계로 벡터나 행렬을 변환하는 과정을 의미합니다. 회전 행렬의 기준 변경은 다음과 같은 수식으로 표현됩니다:

$R_{\text{new}} = C \cdot R_{\text{original}} \cdot C^T$

- $R_{\text{original}}$: 원래 좌표계에서의 회전 행렬.
- $C$: 좌표계 변환을 위한 회전 행렬.
- $R_{\text{new}}$: 새로운 좌표계에서의 회전 행렬.

이 공식은 회전 행렬이 새로운 좌표계에서 올바르게 표현되도록 합니다.

### 5.3 상대 포즈(Relative Pose) 계산

상대 포즈는 한 객체가 다른 객체에 대해 어떻게 위치하고 회전하는지를 나타냅니다. 수학적으로, 카메라 프레임에서 타겟의 상대 포즈는 다음과 같이 계산됩니다:

- **상대 위치**:
    $T_{\text{tgt in cam}} = R_{\text{cam}}^T \cdot ($\mathbf{p}_{\text{tgt}} - $\mathbf{p}_{\text{cam}})$
  
- **상대 회전**:
    $R_{\text{tgt in cam}} = R_{\text{cam}}^T \cdot R_{\text{tgt}}$

여기서:
- $R_{\text{cam}}$: 카메라의 회전 행렬.
- $R_{\text{tgt}}$: 타겟의 회전 행렬.
- $\mathbf{p}_{\text{cam}}$: 카메라의 위치 벡터.
- $\mathbf{p}_{\text{tgt}}$: 타겟의 위치 벡터.

이 계산을 통해 타겟의 포즈가 카메라 프레임에서 어떻게 변하는지를 파악할 수 있습니다.

## 좌표 변환 과정

### 6.1 데이터 로드

```matlab
clear all;
close all;
clc;
jsonPath   = '20241227_C_test4.json';   % JSON 파일 (추정된 포즈)
folderPath = '20241227_test4.db3';      % ROS2 bag (.db3) 파일 (지상 진리 데이터)

% ROS2 bag 파일 읽기
bagReader  = ros2bagreader(folderPath);
msgs       = readMessages(bagReader);
N = length(msgs);  % 총 프레임 수

% 데이터 저장 배열 초기화
cam_pos_world  = zeros(N,3);
cam_quat_world = zeros(N,4);
tgt_pos_world  = zeros(N,3);
tgt_quat_world = zeros(N,4);

% 각 프레임별 데이터 추출
for i = 1:N
    d = msgs{i}.data;
    cam_pos_world(i,:)  = d(1:3);
    cam_quat_world(i,:) = d(4:7);
    tgt_pos_world(i,:)  = d(8:10);
    tgt_quat_world(i,:) = d(11:14);
end
```

### 6.2 쿼터니언을 회전 행렬로 변환

```matlab
% 회전 행렬 저장 배열 초기화
R_cam_in_world = zeros(3,3,N);
R_tgt_in_world = zeros(3,3,N);

% 쿼터니언을 회전 행렬로 변환
for i = 1:N
    R_cam_in_world(:,:,i) = quat2rotm(cam_quat_world(i,:));
    R_tgt_in_world(:,:,i) = quat2rotm(tgt_quat_world(i,:));
end
```

### 6.3 좌표계 정렬

```matlab
% 알고리즘의 포즈 추정 데이터 로드
jsonText = fileread(jsonPath);
algData  = jsondecode(jsonText);

% 포즈 추정 데이터 저장 배열 초기화
R_tgt_in_cam_alg = cell(N,1);
t_tgt_in_cam_alg = zeros(N,3);

% 포즈 추정 데이터 추출
for i = 1:N
    R_arr = algData(i).kf_rotation_matrix;
    t_arr = algData(i).kf_translation_vector;

    R_tgt_in_cam_alg{i} = reshape(R_arr, [3,3]);
    t_tgt_in_cam_alg(i,:) = t_arr;
end

% 좌표계 변환 행렬 정의 (OptiTrack -> OpenCV)
R_alignment = [1,  0,  0; 
              0, -1,  0; 
              0,  0, -1];
           
% 변환 후 저장할 배열 초기화
R_tgt_in_cam_opt = cell(N,1);
t_tgt_in_cam_opt = zeros(N,3);
R_cam_in_pnp_opt = cell(N,1);

% OpenCV 좌표계로 정렬된 위치 저장 배열 초기화
cam_pos_opencv = zeros(N,3);
tgt_pos_opencv = zeros(N,3);

% 좌표 변환 수행
for i = 1:N
    %% 1) 카메라 회전 정렬
    R_cam_in_pnp_opt{i} = R_alignment * R_cam_in_world(:,:,i) * R_alignment';
    
    %% 2) 타겟 회전 정렬
    R_tgt_in_world_aligned = R_alignment * R_tgt_in_world(:,:,i) * R_alignment';
    
    %% 3) 카메라 프레임에서의 타겟 회전 계산
    R_tgt_in_cam_opt{i} = R_cam_in_pnp_opt{i}' * R_tgt_in_world_aligned;
    
    %% 4) 위치 벡터 정렬
    cam_pos_opencv(i,:) = (R_alignment * cam_pos_world(i,:)')';
    tgt_pos_opencv(i,:) = (R_alignment * tgt_pos_world(i,:)')';
    
    %% 5) 카메라 프레임에서의 타겟 상대 위치 계산
    t_tgt_in_cam_opt(i,:) = ( ...
        R_cam_in_pnp_opt{i}' * (tgt_pos_opencv(i,:) - cam_pos_opencv(i,:))' ...
    )';
end
```

### 6.4 상대 포즈 계산

상대 포즈는 카메라 프레임에서 타겟의 위치와 회전을 나타내며, 이는 포즈 추정 알고리즘의 결과와 비교하여 알고리즘의 정확성을 평가하는 데 사용됩니다.

- **상대 위치**:
    $t_{\text{tgt in cam}} = R_{\text{cam}}^T \cdot (p_{\text{tgt}} - p_{\text{cam}})$

- **상대 회전**:
    $R_{\text{tgt in cam}} = R_{\text{cam}}^T \cdot R_{\text{tgt}}$

이를 통해 카메라 프레임에서 타겟의 정확한 위치와 방향을 파악할 수 있습니다.

## 시각화

```matlab
% 3D 플롯 초기화
figure; hold on; grid on; axis equal;
xlabel('X (m)');
ylabel('Y (m)');
zlabel('Z (m)');
title('3D Relative Poses with Cameras and Axes');

% quiver의 스케일 설정
scale = 0.1;

% 각 프레임별 시각화
for i = 1:N
    % OptiTrack 카메라 회전 축 시각화
    quiver3(0, 0, 0, scale*R_cam_in_pnp_opt{i}(1,1), scale*R_cam_in_pnp_opt{i}(2,1), scale*R_cam_in_pnp_opt{i}(3,1), 'Color', [1, 1, 0]); % X축: 노란색
    quiver3(0, 0
